<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
	<channel>
		<title>Posts on Jared Clark</title>
		<link>https://jaredclark0626.github.io/posts/</link>
		<description>Recent content in Posts on Jared Clark</description>
		<generator>Hugo -- gohugo.io</generator>
		<language>en-us</language>
		<copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright>
		<lastBuildDate>Sun, 03 Oct 2021 09:47:21 -0400</lastBuildDate>
		<atom:link href="https://jaredclark0626.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
		
		<item>
			<title>Docker 101</title>
			<link>https://jaredclark0626.github.io/posts/docker-101/</link>
			<pubDate>Sun, 03 Oct 2021 09:47:21 -0400</pubDate>
			
			<guid>https://jaredclark0626.github.io/posts/docker-101/</guid>
			<description>Intro In this tutorial I will be talking about Docker and how to leverage docker in your environment. We will talk about how to install docker on your local machine, using docker, building containers with docker, docker architecture, and orchestration of docker containers. So let&amp;rsquo;s get started by talking about &amp;lsquo;What is Docker&amp;rsquo;. What is Docker? Docker is an open platform for developing, shipping, and running applications. Docker enables you to separate your applications from your infrastructure so you can deliver software quickly.</description>
			<content type="html"><![CDATA[<h1 id="intro">Intro</h1>
<p>In this tutorial I will be talking about Docker and how to leverage docker in your environment. We will talk about how to install docker on your local machine, using docker, building containers with docker, docker architecture, and orchestration of docker containers. So let&rsquo;s get started by talking about &lsquo;What is Docker&rsquo;.
<img src="/img/Docker101Img/image-0.png" alt="image-0"></p>
<h2 id="what-is-docker">What is Docker?</h2>
<p>Docker is an open platform for developing, shipping, and running applications. Docker enables you to separate your applications from your infrastructure so you can deliver software quickly. With Docker, you can manage your infrastructure in the same ways you manage your applications.</p>
<p>Developers can create containers without Docker, but the platform makes it easier, simpler, and safer to build, deploy and manage containers. Docker is essentially a toolkit that enables developers to build, deploy, run, update, and stop containers using simple commands and work-saving automation through a single API.</p>
<p>Docker is an open source containerization platform. It enables developers to package applications into containers—standardized executable components combining application source code with the operating system (OS) libraries and dependencies required to run that code in any environment</p>
<p>Docker carves up a computer into sealed containers that run your code and gets your code to and from your computer. Docker is responsible for building these container and running code inside these container in an isolated controlled environment. There is a docker network where you can share and utilize other users predefined containers. Docker Is NOT a VM but an abstraction of a VM. This means you can have multiple containers running on a single VM all doing a specific job for your application to run.</p>
<h2 id="what-is-a-container">What is a container?</h2>
<p>A container is a self-contained unit of software where it has everything it needs to run the code. A container includes code, configs, processes, networking , all of its dependencies and the operating system.
<img src="/img/Docker101Img/image-0.png" alt="image-0"></p>
<p>For example, you could have a container running  that has a database instance running with all of its storage and a virtual network attached to that container which can talk to another container running your Web Server. Docker is responsible for building, deploying and tearing down this  containerized environment.</p>
<p>Some things you should know before continuing with this tutorial would include the following:</p>
<ul>
<li>Basic command-line environment experience</li>
<li>Basic networking knowledge</li>
<li>PowerShell, Bash, and/or shell scripting</li>
</ul>
<h2 id="how-to-install-docker">How to install Docker?</h2>
<p>To get the MSI or EXE to install docker on your local system then click on the link below:</p>
<ul>
<li>Docker install - <a href="https://docs.docker.com/get-docker/">https://docs.docker.com/get-docker/</a></li>
</ul>
<p>In this tutorial we will be installing docker for windows but feel free to download the installer for your system. Once downloaded then you can open the download which will start the download process to your local system. If you are installing docker on windows then it will require that Hyper-V is enabled for the base VM image for the containers to be provisioned from. It will prompt your to enable Hyper-V on your local Windows machine. Please note, once the docker installation is completed it will prompt you to restart your local system. This is required because docker will be updating the Kernel on your local system to run containers.</p>
<p>After your computer restarts, open a command line interface and run the following command to download the default docker image.</p>
<ul>
<li>Command: docker run hello-world</li>
</ul>
<p>Now you have downloaded the default docker image for the hello-would container to run on your local system.</p>
<h2 id="using-docker">Using Docker?</h2>
<p>Now that docker is installed on your local system we will talk about docker commands and how to start using docker. Let&rsquo;s take a minute and talk about docker flow. The docker flow all starts with an image which makes up just about every file that is needs for a container to operate. The command below allows you to look at all the docker images downloaded to your local system:</p>
<ul>
<li>Command: docker images
<img src="/img/Docker101Img/image-2.png" alt="image-2"></li>
</ul>
<p>As you can see there is some information displayed about the images downloaded to my local machine. Here you see a few column which are defined below:</p>
<ul>
<li>Repository – Name of the image</li>
<li>Tag – Version of the image</li>
<li>Image ID – Unique ID for that version of the image</li>
<li>Created – Date of created image</li>
<li>Size – The size of the image</li>
</ul>
<p>Tip: to remove and image you can run the following command:</p>
<ul>
<li>Command: docker rmi [image_id]</li>
</ul>
<p>Now that we have an image we can create a container off of that image that will be a living running isolated environment for our code to run.<br>
<img src="/img/Docker101Img/image-3.png" alt="image-3"></p>
<h2 id="docker-run">Docker run</h2>
<p>To create a container off the any image download you can run the following command:</p>
<ul>
<li>Command: docker run –ti ubuntu:latest bash</li>
</ul>
<p>Tip: &ndash;ti – Terminal interactive, which means you can navigate through the container when it is running.
<img src="/img/Docker101Img/image-4.png" alt="image-4"></p>
<p>To exit the container bash terminal, simple type &lsquo;exit&rsquo; or &lsquo;CTRL + D&rsquo;. This will allow you to exit the terminal of the running container. If you do not include the &lsquo;-ti&rsquo; parameter into the docker run command there would be no output in the terminal.
<img src="/img/Docker101Img/image-5.png" alt="image-5"></p>
<h2 id="view-docker-containers">View Docker Containers</h2>
<p>If you want to view all the running containers you can use the command below:</p>
<ul>
<li>Command: docker container ls –a
<img src="/img/Docker101Img/image-6.png" alt="image-6"></li>
</ul>
<p>Tip – The parameter &lsquo;-a&rsquo; list all running containers.</p>
<p>Let&rsquo;s quickly talk about the information displayed from the output above. The &lsquo;Container ID&rsquo; is a unique ID assigned to the container during the container provisioning process. Please note, this is not the same ID as the &lsquo;Image ID&rsquo;.</p>
<ul>
<li>Image – Image that the container is provisioned from</li>
<li>Command – Command type</li>
<li>Create – Time the container was created.</li>
<li>Status – Last know status from container</li>
<li>Name – Unique name for provisioned container</li>
</ul>
<p>To stop a running container you can run the following command:</p>
<ul>
<li>Command: docker stop [container_name]
When creating container you might run into an instance where you make a change to the container that you want to keep for all newly created containers. Docker has a feature known as &lsquo;Docker commit&rsquo; which allows you to create an image off the modified container. Please note, this does not affect the original image the container is provisioned from but creates an entirely new image from the updated container.
<img src="/img/Docker101Img/image-7.png" alt="image-7"></li>
</ul>
<h2 id="docker-commit">Docker Commit</h2>
<p>To create an image from an updated container then follow the steps below:
Create a container from the base image:</p>
<ul>
<li>Command: docker run –ti ubuntu:latest bash
Modify the container(create a new file):</li>
<li>Command: touch New-File
Exit the container:</li>
<li>Command: exit
List the latest container(grab the &lsquo;container id&rsquo;):</li>
<li>Command: docker container ls –l<br>
Create a new image off container:</li>
<li>Command: docker commit [container_id]
This will output a long string but what you want to grab is the string(image id) after the semi-colon and create a tag for your newly create image.</li>
<li>Command: docker tag [image_id] [tag_name]
<img src="/img/Docker101Img/image-8.png" alt="image-8"></li>
</ul>
<p>To list the new container with the tag then run the following command:</p>
<ul>
<li>Command: docker images
<img src="/img/Docker101Img/image-9.png" alt="image-9"></li>
</ul>
<p>Now we have a newly created images with the changes we made in the container that we can use to provision new containers. To create a new container off the images we just created then you can run the following command:</p>
<ul>
<li>Command: docker run –ti my-new-image bash
<img src="/img/Docker101Img/image-10.png" alt="image-10"></li>
</ul>
<p>You can skip the tag creation process for the newly created image by running the following command in your docker commit:</p>
<ul>
<li>Command: docker commit [container_name] [tag]
<img src="/img/Docker101Img/image-11.png" alt="image-11"></li>
</ul>
<h2 id="docker-attachdetach">Docker Attach/Detach</h2>
<p>Let&rsquo;s take some time and talk about the most important concept in docker which is running things in docker.  The docker run command provisions a container off an image which contains a main process and when the container stops the process stops. One thing to note here would be docker containers have one main process and when that process completes the container de-provisions. Up until this point we have been running containers in an interactive session and exiting the container. If we want to run a container and run a process then remove the container we can run the following command as an example:</p>
<ul>
<li>Command: docker run –rm –ti ubuntu sleep 5</li>
</ul>
<p>Tip: The –rm parameter is a commonly used parameter to de-provision the container once the container finishes running its main process. This is used for easy clean-up when provisioning containers. Additionally, you can notice I have didn&rsquo;t include the &lsquo;latest&rsquo; tag in my command so docker understands if no tags are included for the image it will grab the latest.</p>
<p>When running the command above it will provision a container from the ubuntu image and pass in the &lsquo;sleep 5&rsquo; bash command which will sleep the container for 5 seconds and once that process is completed it will de-provision the container.  We can pass in multiple commands into the container by running the following command:</p>
<ul>
<li>Command: docker run –ti ubuntu bash –c &ldquo;sleep 3; echo all done&rdquo;</li>
</ul>
<p>Tip: By adding the &lsquo;-c&rsquo; parameter into the docker command we can pass in commands we want to run on the container for its main process. Additionally, you can pass in commands by separating them with a semi-colon. So the command listed above will provision a container and run a bash command to sleep the console for 3 seconds then echo &lsquo;all done&rsquo;. Once finished running the commands it will de-provision the container.<br>
<img src="/img/Docker101Img/image-12.png" alt="image-12"></p>
<p>Let&rsquo;s talk about leaving things run in a container. If we want to provision a container and have it keep running in the background we could run the following command:</p>
<ul>
<li>Command: docker run –d –ti ubuntu bash</li>
</ul>
<p>Tip: The parameter &lsquo;-d&rsquo; allows the container to run in detached mode which means the container will run in the background until the main process is completed or is de-provisioned. Since we passed in the &lsquo;bash&rsquo; command that means this container will run forever until it is de-provisioned. If we get the name of the container we can run a docker command to attach to the container to run another process or exit the terminal.</p>
<p>Get the container name of the last run container:</p>
<ul>
<li>Command: docker container ls –l
Attach to the container:</li>
<li>Command: docker attach [container_name]
<img src="/img/Docker101Img/image-13.png" alt="image-13"></li>
</ul>
<p>Now what happens if you want to run more things in an already provisioned container. For example, we create a container and pass in the &lsquo;bash&rsquo; command to open a session to the command –line then we want to add a process to that container from troubleshooting purposes we could leverage the &lsquo;docker exec&rsquo; command. This command is used to add/start another process to the running container. Please note, you cannot use this command for adding port, volumes, networking, etc. To run the docker exec command to an already running container you can run the following commands:</p>
<ul>
<li>Command: docker exec [container_name] bash
<img src="/img/Docker101Img/image-14.png" alt="image-14"></li>
</ul>
<p>This will allow us to open a bash session to an already running container for troubleshooting purposes. Sometimes we want to look at the logs for a container that is having trouble running its main process and in that case we can use the &lsquo;docker logs&rsquo; command. To set this up we will run a docker run command and pass in an invalid Bash command. This will run in the background and fail which in turn we will run the docker logs command to see what caused the issue.</p>
<ul>
<li>Broken command: docker run –name example –d ubuntu bash –c &ldquo;lose /etc/password&rdquo;</li>
<li>Logs command: docker logs example
<img src="/img/Docker101Img/image-15.png" alt="image-15"></li>
</ul>
<h2 id="stopdelete-containers">Stop/Delete Containers</h2>
<p>In order to stop and remove a running container you first need to stop the running container and then delete the container. Simply stopping the container will not automatically delete the container.</p>
<ul>
<li>Stop container: docker kill [container_name]</li>
<li>Delete container: docker rm [container_name]
Tip: To stop and delete all running container then you can run the following commands:</li>
<li>Stop all containers: docker kill $(docker ps –q)</li>
<li>Delete all containers: docker rm $(docker ps –a –q)</li>
</ul>
<p>When running a docker container you have the ability to allocate specific resources to a single container. If we want to allocate a specific amount of memory to a container we can run the following command:</p>
<ul>
<li>Command: docker run –memory [max_memory] [image_name] [command]
Tip: To allocate  CPU limits to a container you can run the following command:</li>
<li>Command: docker run –cpu-shares – Containers running will share the CPU resources</li>
<li>Command: docker run –cpu-quota – Limits the CPU resources allocated to containers</li>
</ul>
<h2 id="exposing-ports">Exposing Ports</h2>
<p>By default when provisioning a container it is isolated from the internet which means it is part of your local private network. You can explicitly expose a container to the internet by opening ports on your container to allow traffic in and out of your container. Exposing ports in your container allows your container running on a private network to talk to things outside your private network. When exposing a port you need to explicitly specify the port inside the container and outside. You can expose any amount of ports and coordination between containers is required it you want containers to talk to one another. Below is an example with two running containers with ports exposed to one another and a third container to watch the traffic:</p>
<ul>
<li>Container one command: docker run –-rm –ti –p 45678:45678 –p 45679:45679–-name container-one ubuntu bash</li>
</ul>
<p>Tip: The –p docker command stand for &lsquo;Publish&rsquo; which defines which ports you want to open. As you can see there are two ports defined separated by a colon. The first port is the ingress port and the second port is the egress port.</p>
<p>Once inside the container we can run a net cat program to see if the port is open and what traffic flow in and out of the container:</p>
<ul>
<li>Container one command: nc –lp 45678 | nc –lp 45679</li>
</ul>
<p>Open a second terminal window and create the second container that will talk to the first container.</p>
<ul>
<li>Container two command: docker run –-rm –ti ubuntu:14.04 bash</li>
<li>Container two command: nc host.docker.internal 45678</li>
</ul>
<p>Open a third command window and provision a third container to watch the traffic:</p>
<ul>
<li>Container two command: docker run –-rm –ti ubuntu:14.04 bash</li>
<li>Container two command: nc host.docker.internal 45679</li>
</ul>
<p>Back in the second container type whatever you would like and watch the text from one container into another.
<img src="/img/Docker101Img/image-16.png" alt="image-16"></p>
<p>You can dynamically open external ports to the container by not specifying the second port. For example, you can run the following docker command which is open the internal port 45678 and dynamically open the external port which docker will define.</p>
<ul>
<li>Command: docker run –-rm –ti –p 45678 –-name container-one ubuntu bash</li>
</ul>
<p>To define a specific protocol for the traffic coming through the ports you can run the following command:</p>
<ul>
<li>Command: docker run –p [outside-port:inside-port]/[tcp/udp]</li>
</ul>
<h2 id="docker-networking">Docker Networking</h2>
<p>When exposing a port in Docker it creates a path from the container to the host network. Other containers can connect to that container by going out of its container into the host network and back into the container it is talking with.<br>
<img src="/img/Docker101Img/image-17.png" alt="image-17"></p>
<p>Docker comes with some networks by default. To look at the default networks you can run the following commands:</p>
<ul>
<li>Command: docker network ls
<img src="/img/Docker101Img/image-18.png" alt="image-18"></li>
</ul>
<p>Types of networks described below:</p>
<ul>
<li>Bridge Network – Defines the default network the containers are deployed.</li>
<li>Host Network – Host machine network and when you do not want the container to have an isolation at all. This poses security threats and should not be used except for testing.</li>
<li>None – Defines if the container should have no networking at all.</li>
</ul>
<p>Now let&rsquo;s create a &lsquo;testing&rsquo; virtual network in docker. To create a virtual network run the commands below:</p>
<ul>
<li>Command: docker network create testing</li>
</ul>
<p>Once the network is created we can add a container to the at virtual network by running the following command:</p>
<ul>
<li>Command: docker run –rm –ti –net testing –name container-one ubuntu:14.04 bash</li>
</ul>
<p>To test the container network you can ping the name of the container name from inside the bash terminal by running the following command:</p>
<ul>
<li>Command: ping container-one
<img src="/img/Docker101Img/image-19.png" alt="image-19"></li>
</ul>
<p>If you want to start second container in the same network and ping container one from the second container you can run the following commands:</p>
<ul>
<li>Command:  docker run –rm –ti –net testing –name container-two ubuntu:14.04 bash</li>
<li>Command: ping container-one
<img src="/img/Docker101Img/image-20.png" alt="image-20"></li>
</ul>
<p>Tip: To connect a running container to another network you could create a second network called &lsquo;network-1&rsquo; and run the following command to add it to both &lsquo;testing&rsquo; and &lsquo;network-1&rsquo; networks.</p>
<ul>
<li>Command: docker network connect network-1 container-one</li>
</ul>
<h2 id="docker-volumes">Docker Volumes</h2>
<p>Let&rsquo;s talk about sharing data across containers. Docker using &lsquo;volumes&rsquo; as a shared folder that can be used across various containers. With volumes you can share data between containers running in docker and share data between the host and the containers. There are two types of volumes in docker which are defined below:</p>
<ul>
<li>Persistent – The volume on the host machine will stay consistent when containers are using said volume</li>
<li>Ephemeral – These volumes exist only when the container is using them. When the container stops the volume is deleted.</li>
</ul>
<p>Let&rsquo;s share a folder from our local machine(host) to a container. First, create a folder on your local machine.</p>
<ul>
<li>Command: mkdir example</li>
</ul>
<p>Once the folder is created on the host machine you can run the following command to create a container with the volume attached:</p>
<ul>
<li>Command: docker run –ti –v C:\Users\jclar\example:/shared-folder ubuntu bash</li>
</ul>
<p>Create a &lsquo;data&rsquo; folder inside the shared-folder in the container:</p>
<ul>
<li>Command: touch /shared-folder/data</li>
</ul>
<p>Exit the container and navigate to the &lsquo;example&rsquo; folder on your local machine to see the persistent data flow from the container to the host machine.
<img src="/img/Docker101Img/image-21.png" alt="image-21"></p>
<p>Tip: If you want to share a single file from the host machine to the container you need to explicitly list the files entire path. Additionally, you will need to make sure the file exists on the host machine because if the file does not exist it will create a folder with the file name on the container.</p>
<p>Now let&rsquo;s create a shared volume between two containers. This volume is Ephemeral and will only exist when the containers are running.</p>
<ul>
<li>Command: docker run –ti –v /shared-data ubuntu bash</li>
</ul>
<p>Tip: The –v parameter used in this case will create a shared folder on the container NOT on the host.</p>
<p>Put some data in the share-data folder by running the following command on the container:</p>
<ul>
<li>Command: echo hello-world &gt; /shared-data/data-file
Now let&rsquo;s start up another container.</li>
<li>Command: docker run –ti –volumes-from [container_name] ubuntu bash</li>
</ul>
<p>If you navigate to that file on the second container you will see the data. You can update the data-file and it will get updated on the first container. When both container stops it will get removed from both containers but if one container stops even if it’s the first container the shared folder will still exist on the second container. Only when all containers using that shared folder stop then the shared volume will get deleted.</p>
<p>Now we are just scratching the surface of what docker can do and it upcoming blogs we will take a deeper dive into what docker. I hope you enjoyed reading this blog and I will see you in the next one.</p>
]]></content>
		</item>
		
		<item>
			<title>Introduction to ARM Templates</title>
			<link>https://jaredclark0626.github.io/posts/introduction-to-arm-templates/</link>
			<pubDate>Sat, 01 Aug 2020 08:19:17 -0400</pubDate>
			
			<guid>https://jaredclark0626.github.io/posts/introduction-to-arm-templates/</guid>
			<description>Short-hand:
 ARM - Azure Resource Manager Azure DevOps - ADO CI/CD Pipelines - CI\CD  Introduction In this blog I will talk about Azure Resource Manager (ARM) templates and how we can implement them into a CI\CD pipeline in Azure DevOps. First, I will give a high level overview of ARM architecture and then I will dig into how we can automate cloud infrastructure using ARM templates in an orchestration tool such as Azure DevOps.</description>
			<content type="html"><![CDATA[<p>Short-hand:</p>
<ul>
<li>ARM - Azure Resource Manager</li>
<li>Azure DevOps - ADO</li>
<li>CI/CD Pipelines - CI\CD</li>
</ul>
<h2 id="introduction">Introduction</h2>
<p>In this blog I will talk about Azure Resource Manager (ARM) templates and how we can implement them into a CI\CD pipeline in Azure DevOps. First, I will give a high level overview of ARM architecture and then I will dig into how we can automate cloud infrastructure using ARM templates in an orchestration tool such as Azure DevOps. Let&rsquo;s start by giving an overview of ARM templates.</p>
<h2 id="arm-templates-overview">ARM Templates Overview</h2>
<p><img src="/img/IntroductionToARMTemplates/image0.png" alt="Image0"></p>
<p>With the technology world moving faster than ever, a lot of organizations have adopted the agile development methodology. As organization want to ship code faster they need a way to deploy infrastructure consistently and reliably throughout their environments. With the DevOps movement, organizations have torn down the silos between teams such as IT and Development. Now the infrastructure and application developments are in a single unified process.</p>
<p>This is where Azure Resource Manager (ARM) templates come into play. ARM Templates give us a was to define out infrastructure as code. This aligns with the agile methodology by being consistent and reliable when deploying our infrastructure across multiple environments such as DEV, QA, UAT and Production. Since build infrastructure is now part of the Software Development Life Cycles we can store the ARM Templates infrastructure as code into repositories and iterate over them when new requirements are handed down.</p>
<p>This allows for any team member on either the infrastructure or application team to deploy infrastructure changes at any given time. ARM Templates is a JavaScript Object Notation (JSON) file that defines the Infrastructure and configuration for your environments. The syntax is declarative and allows you to state what you intend to deploy without having to write the programming commands to provisioned the infrastructure. Now that we have a basic understanding of ARM templates, lets dig into the architecture of the Azure Resource Manager.</p>
<h2 id="azure-resource-manager-architecture">Azure Resource Manager Architecture</h2>
<p>I want to start by saying modern Azure functionality is build on Azure Resource Manager ARM and Azure deployment services. Prior to Azure Resources Manager there was an Azure Service manager(ASM). This service was limited and is why Microsoft created Azure Resource Manager(ARM). With ARM, all APIs and management interfaces operate by using the ARM layer in Azure. One of the biggest differences between ARM and ASM is ARM gives us the ability to run parallel operations at once. Additionally, ARM includes the following:</p>
<ul>
<li>Azure PowerShell</li>
<li>Azure CLI</li>
<li>REST APIs</li>
<li>SDKs</li>
<li>Azure AD</li>
<li>Azure Authentication</li>
</ul>
<p>ARM uses a declarative concept, which means you tell ARM what you want in an ARM template and then the Azure ARM layer provisions those resources. For example, if we need to provision a VM inside of a Virtual Network we would write the declarative state in the ARM template. The Azure ARM layer knows that VMs have a network dependency and would build the network prior to provisioning the VM.</p>
<p><img src="/img/IntroductionToARMTemplates/image1.png" alt="Image1"></p>
<p>Keep in mind since ARM is using a declarative state that means if we run the template once it will provision the resources specified in the ARM template. Now if we run the template a second time it will not re-provision those resources, unless there is a change to the ARM template modifying the existing resources or adding new ones. All the Azure resource types are provided by Azure resource providers. These resources types are then specified in the ARM template depending on which type of resource type you want to provision.</p>
<p>To view resource types, Azure provides a tool called Azure Resource Explorer which allows you to view all resources types.</p>
<p>Azure Resource Explorer - <a href="https://azure.microsoft.com/en-us/blog/azure-resource-explorer-a-new-tool-to-discover-the-azure-api/">https://azure.microsoft.com/en-us/blog/azure-resource-explorer-a-new-tool-to-discover-the-azure-api/</a></p>
<p>Resources are an important component when it comes to ARM templates. They will be used as building blocks when building out your infrastructure. Resources will often reference other resources and depend on other resources in Azure. For example, lets same we want to provision a VM in Azure. VMs are dependent on disks to be provisioned first then mounted to the VM. So the in this case the VM is dependent on the disk. Depending how you build out you infrastructure you will have many dependencies on various Azure resources.</p>
<p><img src="/img/IntroductionToARMTemplates/image2.png" alt="Image2"></p>
<p>All the configurations done to your ARM templates are in JSON format and deployments are internally stored in a JSON file in an ARM template. JSON format is easy to read and to understand. I would prefer the template format to be in YAML but I digress. Each resource group in Azure has an option to export the ARM template. If you navigate to a resource group and click on &lsquo;Export Template&rsquo; under the settings pane you will see the ARM template in JSON format.</p>
<p>Resource groups offer us logical buckets to place our resources in. Resource groups are fundamental to ARM templates. Resources groups provide various benefits which are outlined below:</p>
<ul>
<li>We should group resources with the same or similar lifecycle together.</li>
<li>Role based access control is typically applied at the resource group level.</li>
<li>Policies are applied at the resource group level.</li>
<li>Tags can be applied and configured at the resource group level.</li>
</ul>
<p><strong>Please note, resources can only be placed in one resources group. You can not have a single resource attached to multiple resource groups.</strong></p>
<h2 id="arm-templates">ARM Templates</h2>
<p>In this section we will cover the structure of an ARM template, various sources of ARM templates, template deployment process and Azure portal ARM template repositories. Lets start by talking about the ARM template structure.</p>
<h3 id="arm-template-structure">ARM Template Structure</h3>
]]></content>
		</item>
		
		<item>
			<title>Monitoring And Diagnostics App Service Plan</title>
			<link>https://jaredclark0626.github.io/posts/monitoring-and-diagnostics-app-service-plan/</link>
			<pubDate>Mon, 25 May 2020 10:34:37 -0400</pubDate>
			
			<guid>https://jaredclark0626.github.io/posts/monitoring-and-diagnostics-app-service-plan/</guid>
			<description>tags:
 App Service Plans App Service Azure Monitoring Diagnostics   Short-hand:
 AS - App Service ASP - App Service Plan  This will be the last blog in this series for Managing Azure App Services plans. In this blog I will give you an overview on monitoring and diagnostics for App Service plan. We will cover enabling logging, configuring logging, monitoring metrics and Application insights. Now let&amp;rsquo;s get into an overview of Monitoring and Diagnostics for App Service Plans.</description>
			<content type="html"><![CDATA[<hr>
<p>tags:</p>
<ul>
<li>App Service Plans</li>
<li>App Service</li>
<li>Azure</li>
<li>Monitoring</li>
<li>Diagnostics</li>
</ul>
<hr>
<p>Short-hand:</p>
<ul>
<li>AS - App Service</li>
<li>ASP - App Service Plan</li>
</ul>
<p>This will be the last blog in this series for Managing Azure App Services plans. In this blog I will give you an overview on monitoring and diagnostics for App Service plan. We will cover enabling logging, configuring logging, monitoring metrics and Application insights. Now let&rsquo;s get into an overview of Monitoring and Diagnostics for App Service Plans.</p>
<p>Overview of Monitoring and Diagnostics</p>
<p>There are two categories for capturing Monitoring and Diagnostics for an App Service Plan. First, we have Azure monitor which monitors the App Service plan. Next, there is Azure Logging which captures logs for your application running in an App Service plan. Those logs can be stored either on the App Service server or in an Azure Storage container. Let discuss these two categories in depth.</p>
<p><img src="/img/MonitoringAndDiagnosticsAppServicePlan/image1.png" alt="Image1"></p>
<p>Azure Monitor</p>
<p>Azure monitor service can collect telemetry metrics for you App Service Plan. This collection of metrics can either happen on you on-premise or Azure environment. Some of the basic metrics Azure Monitor can collect include:</p>
<ul>
<li>CPU Usage</li>
<li>Memory Usage</li>
<li>I/O Usage</li>
</ul>
<p>Here is a link to a full list of metrics Azure Monitor can collect - <a href="https://docs.microsoft.com/en-us/azure/azure-monitor/platform/metrics-supported">https://docs.microsoft.com/en-us/azure/azure-monitor/platform/metrics-supported</a></p>
<p>We can also setup alerts in Azure Monitor when specific metric thresholds are reached. One thing to note is Azure Monitor includes Azure Log Analytics and Application Insights. For Azure monitor we are charged on per GB usage. Log Analytics is an Analytics engine and management solution which includes its own query language. With Log Analytics the management solution collects data from various sources which then can be queued with pre-defined queries Log analytics provides.</p>
<p>Application Insights monitors the overall health of your App Service Plan. This can monitor your App availability, App Performance, and App usage. You can configure Application insights either internally which will include code changes or externally which does not include code changes. There are visualization tools build into Application insights that allows you to get a high-level graphical view of your application. This allows you to see how data is flowing through your application. Application insights supports a verity of languages whether they are supported by Microsoft or the community.</p>
<p>Link to what languages are supported by Application Insights - <a href="https://docs.microsoft.com/en-us/azure/azure-monitor/app/platforms">https://docs.microsoft.com/en-us/azure/azure-monitor/app/platforms</a></p>
<p>Now let&rsquo;s configure Application logging!</p>
<p>Configuring Application Logging</p>
<p>If you are using the ASP.NET or ASP.NET Core framework you can utilize the use predefined system classes to configure application monitoring.</p>
<p>ASP.NET - System.Diagnostics.Trace</p>
<p>ASP.NET Core - ASP.NET Core - Microsoft.Extensions.Logging.AzureAppServices</p>
<p>(Not included in Microsoft.Asp.NetCore.AppMetaPackage)</p>
<p>We can use these classes to log data to a console window and/or add logging to Azure. Open the solution file to you project and open &lsquo;Solution Explorer&rsquo;. Right click on &lsquo;Dependencies&rsquo; and click &lsquo;Manage NuGet Packages&rsquo;. Search for &lsquo;Microsoft.Extensions.Logging.AzureAppServices&rsquo; and install it into your solution.</p>
<p><img src="/img/MonitoringAndDiagnosticsAppServicePlan/image2.png" alt="Image2"></p>
<p>Once installed, if you expand the &lsquo;Nuget&rsquo; folder in your solution you will see the package. Now we will need to configure logging in the main &lsquo;Program.cs&rsquo; file. We need to add a &lsquo;using&rsquo; statement at the top of the program file to use the extension.</p>
<p>Code - &lsquo;using Microsoft.Extensions.Logging;&rsquo;</p>
<p>In the main method in the &lsquo;program.cs&rsquo; program file we want to configure logging by adding the following code to the &lsquo;IWebHostBuilder&rsquo; method.</p>
<p>Code - &lsquo;.ConfigureLogging(logging =&gt; logging.AddAzureWebAppDiagnostics());&rsquo;</p>
<p>IWebHostBuilder method -</p>
<p>public static IWebHostBuilder CreateWebHostBuilder(string[] args) =&gt;</p>
<pre><code>        WebHost.CreateDefaultBuilder(args) 

            .UseStartup&lt;Startup&gt;() 

        .ConfigureLogging(logging =&gt; logging.AddAzureWebAppDiagnostics()); 
</code></pre>
<p>To configure the output for the logging message you can add code to the individual program files in your application. You will need to add the &lsquo;using Microsoft.Extensions.Logging;&rsquo; to the top of the files you are configuring logging on. This allows you to call methods and functions for the NuGet package we added earlier. Once configured we can build the code locally and push it to Azure App Service.</p>
<p>Enabling logging in the Azure App Service</p>
<p>Log into the Azure portal and navigate to the App Service you would like to enable logging. Click on the &lsquo;App Service Logs&rsquo; tab, by default all the logging is turned off. The &lsquo;Application Logging (Filesystem)&rsquo; setting will enable the configuration settings we just applied to out application. These logs will then be written to a local file on the App Service file system. Note: This setting will only be enabled for 12 hours and then will be automatically disabled. This allows for a troubleshooting window. This gets disabled by default because it is resource extensive. There is an option to capture the level of error logging for the web application, which are listed below.</p>
<p>Level</p>
<ul>
<li>Error</li>
<li>Warning</li>
<li>Information</li>
<li>Verbose</li>
</ul>
<p>The logging you specified in code will correspond to the level you set under this option. There will be a &lsquo;LogFiles&rsquo; directory that gets created on the App Service. This is where we can go to grab the logs for troubleshooting. Keep in mind all the files located on the App Service can be streamed from the App Service to your local or a shared drive by using the Azure CLI. This comes in handy when you are troubleshooting issues from the past. Above we mentioned that the log &lsquo;Application Logging(File System)&rsquo; gets disabled by default after 12 hours, we can enable the &lsquo;Application Logging(Blob) which will write the log files to a blob storage container.</p>
<p>There is an option to set the retention on the log files kept in the storage blob. Under the Application Logs section there are options to enable &lsquo;Web Server Logging&rsquo; logging, this allows you to capture http/https and IP address requests from the IIS VM Servers allocated to your App Service Plan. These logs get store on the App Service file structure under the &lsquo;http&rsquo; folder. Additionally, we have an option to capture &lsquo;Detailed Error Messages&rsquo; for the App Service which is linked to the folder named &lsquo;DetailedErrors&rsquo; on the App Service. The last option to enable for logging is called &lsquo;Failed Request Tracing&rsquo;, this allows you to capture the failed request hitting your App Service. The folder on the App Service that corresponds to the &lsquo;Failed Request Tracing&rsquo; is prefixed with &lsquo;W3SVC&rsquo;.</p>
<p>App Service Directory Logging Mapping</p>
<ul>
<li>Application Logging (Filesystem) - .\LogFiles</li>
<li>Web Server Logging - .\http</li>
<li>Detailed Error Message - .\DetailedErrors</li>
<li>Failed Request Tracing - .\W3SVC&hellip;&hellip;.</li>
</ul>
<p><img src="/img/MonitoringAndDiagnosticsAppServicePlan/image3.png" alt="Image3"></p>
<p>There is a tab in the Azure App Service called &lsquo;Log Streaming&rsquo; which allows you to view generated logs in your App Service in real time. This comes in handy when you are troubleshooting an ongoing issue with your App Service. We can which between the &lsquo;Application Logs&rsquo; and the &lsquo;Web Server Logs&rsquo; to view generated logs in real time. There are additional options to clear, pause and start the log streaming. I haven&rsquo;t used this tool much in the past but it may come in hand for you and your team when tracking down complicated issues. We talked about the different types of logs we can generate for and App Service. Next, we will talk about Monitoring your App service by using metrics.</p>
<p>Monitoring Azure App Service</p>
<p>Navigate to your App Service in Azure and click on the &lsquo;Overview&rsquo; tab. At the bottom of the screen we get a few predefined metric graphs that Azure provides out of the box. Azure you allow you to edit each graph by double clicking on the graph. We can choose a time frame we would like to view in the chart by clicking on the &lsquo;Local Time&rsquo; icon on the upper right-hand side of the screen. Also, on the right-hand side we can change the chart type by clicking on the &lsquo;Line Chart&rsquo; drop down and choosing a different type of chart. We can drill down into the chart to see what scope of metrics the graph is showing. Click on the oval with the name of the app service and metric scope.</p>
<p><img src="/img/MonitoringAndDiagnosticsAppServicePlan/image4.png" alt="Image4"></p>
<p>Inside the metric scope we can change the scope of the metric to pull back different data points and configure the aggregation. Azure provide a wealth of data points that you can configure. Another cool feature that Azure provides is it allows you to pull multiple data points back in a single graph. So, we could configure &lsquo;Data In&rsquo; and &lsquo;Data Out&rsquo; in a single graph.</p>
<p><img src="/img/MonitoringAndDiagnosticsAppServicePlan/image5.png" alt="Image5"></p>
<p>We can export the graph in excel format if needed. Additionally, we can pin and rename the graph as needed. Let&rsquo;s look at how we can setup alerts on these metrics!</p>
<p>Setting up Alerts for Metrics</p>
<p>Search for &lsquo;Monitor&rsquo; in Azure and then select the &lsquo;Metrics&rsquo; tab on the left-hand side of the screen. We can scope our metrics to any resource in the Azure subscription. In our case we will be scoping the metrics to the App Service plan we created in a previous blog. When clicking on the &lsquo;Metrics&rsquo; tab a new window will appear to define the scope of the metrics. Select the resource you would like to capture the metrics on and click &lsquo;Apply&rsquo;. This allows you to capture multiple graphs from various Azure resources on a single-pane of glass. I thought I would mention this feature before moving on to setting up alerts for metrics.</p>
<p>Select the &lsquo;Alerts&rsquo; tab and click &lsquo;New Alert Rule&rsquo;. Here we can select the resource that we would like to alert on by selecting the &lsquo;Select Resource&rsquo; link. Select the resource that you would like to alert on a click &lsquo;Done&rsquo;. Under the &lsquo;Condition&rsquo; section we can click &lsquo;Select Condition&rsquo; which will allow us to configure the condition we would like to be alerted on. In our case we are going to select the &ldquo;CPU Percentage&rsquo; metrics. At the bottom of the screen we can narrow down which instances we would like to be alerted on. Since the App Service is running on an App Service Plan there could be multiple instances provisioned depending on auto-scale. In our case we want to be alerted on all instances in the App Service plan.</p>
<p>Under the &lsquo;Alert Logic&rsquo; we can specify when we want to be alerted. For example, we want an alert to be created when the &lsquo;CPU Percentage&rsquo; is &lsquo;Greater than&rsquo; the &lsquo;Average&rsquo; threshold of 70%. There are three options under &lsquo;Alert Logic&rsquo; which will need to be defined for your alert.</p>
<ul>
<li>Condition</li>
<li>Time Aggregation</li>
<li>Threshold</li>
</ul>
<p>Under the &lsquo;Evaluated Based On&rsquo; section we can configure how long this condition needs to be met before sending an alert. For example, if the &lsquo;CPU Percentage&rsquo; exceeds 70% for 5 minutes then we wanted to be alerted. We can configure the &lsquo;Frequency&rsquo; this metric is check by changing the &lsquo;Frequency&rsquo; option to &lsquo;Every 1 Minute&rsquo;. This will allow Azure monitor to check to see if this condition is met every 1 minute. Once configured click &lsquo;Done&rsquo; and an estimated monthly charge will be set showing you how much the alert is going to cost.</p>
<p>Below we can add an &lsquo;Alert Rule Name&rsquo;, &lsquo;Description&rsquo; of the alert and its &lsquo;Severity&rsquo;. There is also another option to &lsquo;Enable rule upon creation&rsquo; which will enable the alert automatically. At the bottom of the screen we can define an action group. This allow us to configure actions to be taken when the alert condition is met. We are going to configure an &lsquo;Action Group&rsquo; to send out an email message to myself when the alert condition is met. Select &lsquo;Create Action Group&rsquo; button and specify the name of the &lsquo;Action Group&rsquo;. Under &lsquo;Actions&rsquo; we are going to name the action &lsquo;Send Email&rsquo; and change the &lsquo;Action Type&rsquo; to &lsquo;Email/SMS/Push/Voice&rsquo;. Under &lsquo;Edit Details&rsquo; we can specify the email address we would like the alert to be send to. Click &lsquo;Ok&rsquo; and then on the &lsquo;Action Group&rsquo; page click &lsquo;Ok&rsquo;</p>
<p>Now we have successfully set up an alert in Azure monitor which is going to send an email out when our condition is met. We have talked about configuring logging for App Services and configuring alerts based on metrics captured in the App Service. This blog will end our series on Managing Azure App Service Plans.</p>
<p>Until next time! Cheers!</p>
<p>Jared Clark</p>
]]></content>
		</item>
		
		<item>
			<title>Optimizing App Service Delivery Azure CDN</title>
			<link>https://jaredclark0626.github.io/posts/optimizing-app-service-delivery-azurecdn/</link>
			<pubDate>Sun, 03 May 2020 11:36:43 -0400</pubDate>
			
			<guid>https://jaredclark0626.github.io/posts/optimizing-app-service-delivery-azurecdn/</guid>
			<description>tags:
 App Service Plans App Service Azure Optimizing   Short-hand:
  Azure CDN - Azure Content Delivery Network
  AS - App Service
  ASP - App Service Plan
  Optimizing App Service using Azure CDN
In this short blog we will talk about optimizing the content delivery to an App Service using Azure Content Delivery Network. This will help us delivery updated versions of our code to Azure CDN to different regions around the world.</description>
			<content type="html"><![CDATA[<p>tags:</p>
<ul>
<li>App Service Plans</li>
<li>App Service</li>
<li>Azure</li>
<li>Optimizing</li>
</ul>
<hr>
<p>Short-hand:</p>
<ul>
<li>
<p>Azure CDN - Azure Content Delivery Network</p>
</li>
<li>
<p>AS - App Service</p>
</li>
<li>
<p>ASP - App Service Plan</p>
</li>
</ul>
<p>Optimizing App Service using Azure CDN</p>
<p>In this short blog we will talk about optimizing the content delivery to an App Service using Azure Content Delivery Network. This will help us delivery updated versions of our code to Azure CDN to different regions around the world. Instead of delivering our code to a specific region in Azure we will distribute our code to multiple regions in Azure using Azure CDN. This allows users from all over the world to quickly access our App. We will also talk about creating a CDN profile/endpoints, configuring caching rules, Dynamic Site Acceleration and Azure CDN App Service auto-scaling.</p>
<p>Overview of Azure CDN</p>
<p>Azure CDN is a distributed network of servers all over the world. These servers store cached data for you content which minimizes latency to users all over the world. The Azure CDN offloads traffic from the source server which typically store static data such as HTML files, photos, videos, etc. Azure CDN can store dynamic data as well which is known as Dynamic Site Acceleration. We will talk more about dynamic site Acceleration later in this blog.</p>
<p><img src="/img/OptimizingAppServiceDeliveryAzureCDN/image1.png" alt="Image1"></p>
<p>At a high level you have an origin server which is typically an Azure App Server, Web App, Blob storage, or Azure Media Services. This origin server stores you content which is then cached over to the Azure CDN server. When making updates to your origin, those updated files get cached to the Azure CDN server. The Azure CDN servers are also known as &lsquo;Edge Servers&rsquo;, these servers are spread out throughout the world. There is something know as &lsquo;Point-of-presence (POP) locations which are located in Azure CDN regions. There are more POP locations then Azure data centers.</p>
<p>Here is an example of how data is received for a user using Azure CDN. The user (located in India) goes to our site &lsquo;<a href="https://AwesomeSite.azureedge.net">https://AwesomeSite.azureedge.net</a>&rsquo; which is known as an endpoint. That endpoint points to an edge server that is located closest to the user&rsquo;s location. That edge server then reaches out to the origin server point pull content and cache it on the specified edge server.</p>
<p><img src="/img/OptimizingAppServiceDeliveryAzureCDN/image2.png" alt="Image2"></p>
<p>There is a setting called &lsquo;Time to live&rsquo; that setting by default is set to 7 days. That setting refers to how long the cached data from the origin server will live on the edge server. If updates are made to the origin server then a purge of the cached data on the edge server will need to be done. You can purge all data on the edge server or you can purge a specific subset of data. Azure CDN is made up of profiles and endpoints. An endpoint is essentially a URL which points to an App Service, Web App, Blob storage, etc. By default, azure CDN endpoints are prefixed with &lsquo;azureedge.net&rsquo;. You can configure an endpoint to point to a custom domain name. A CDN Profile is a collection of endpoints and azure prices at the profile level. Azure CDN features are defined by which provider you choose and which pricing tier.</p>
<p>Link to Azure CDN Pricing Tiers: <a href="https://azure.microsoft.com/en-us/pricing/details/cdn/">https://azure.microsoft.com/en-us/pricing/details/cdn/</a></p>
<p>Creating Azure CDN Profile and Endpoint</p>
<p>For this demo we will be using an existing Azure App Service to configure to an Azure CDN profile/endpoint. Navigate to your app service or content that you would like to configure to an Azure CDN profile/endpoint. On the left-hand side of the screen choose the &lsquo;Networking&rsquo; tab then click on the &lsquo;Configure Azure CDN for your app&rsquo; link. Here you will see an option to create and Azure endpoint. But wait, we need to create an Azure profile before creating an Azure endpoint since Profiles are a collection of endpoints. In the azure portal search for &lsquo;CDN&rsquo; and select the &lsquo;CDN&rsquo; button and click create. This opens a page to create a CDN profile which we need in order to tie our App Service endpoints to a CDN.</p>
<p>When creating a CDN profile you will need to create or use an existing resource group, specify a region to store the resource group and a pricing tier. In our case we will use the Version pricing tier so we can configure Dynamic Site Acceleration.</p>
<p><img src="/img/OptimizingAppServiceDeliveryAzureCDN/image3.png" alt="Image3"></p>
<p>Once the CDN profile is created, let&rsquo;s open it and add an endpoint to our App Service. Click on the plus sign on top of the screen to add an endpoint. Name your endpoint but keep in mind that it will be prefixed with &lsquo;azureedge.net&rsquo; Next, we will choose our origin type, which in our case we are deploying a web app to the Azure CDN so we will choose the &lsquo;Web App&rsquo; option. The Origin hostname is tied to the URL that we are currently using to access our Web App. This should auto-populate with the origin hostname tied to your existing web app. Since we are deploying the entire web app to the CDN we will leave the origin path blank so it uploads the root directory. The origin host header should be the same as the origin hostname. Next, we can define which ports to send the data over from the origin server to the Azure Edge servers. In our case we will keep the default port 80 for http traffic and 443 for https traffic. Lastly, we will choose the &lsquo;General Web delivery&rsquo; option for the &lsquo;Optimized for&rsquo; option.</p>
<p><img src="/img/OptimizingAppServiceDeliveryAzureCDN/image4.png" alt="Image4"></p>
<p>Now it I hit the endpoint URL &lsquo;<a href="https://jcwebapp.azureedge.net/'">https://jcwebapp.azureedge.net/'</a> it points to the web app source server!</p>
<p>Setting up Azure CDN Caching</p>
<p>If you open your content that you are uploading to the CDN which in our case is an Azure Web App and then navigate to the networking tab. Choose the &lsquo;Configure Azure CDN for your app link&rsquo; which opens a new page. Click on the endpoint we just configured and then select the &lsquo;Caching rules&rsquo; tab. By default, the caching settings are set to 7 days. Under &lsquo;Caching behavior&rsquo; we have a few option listed below:</p>
<ul>
<li>
<p>Not set - Inherits default caching settings</p>
</li>
<li>
<p>Bypass Cache - Ignores caching settings all together.</p>
</li>
<li>
<p>Override - Overrides the default caching settings.</p>
</li>
<li>
<p>Set if missing - Will inherit any caching setting set on origin server (Web App).</p>
</li>
</ul>
<p>Let select the &lsquo;Override&rsquo; option and then change the &lsquo;Caching expiration duration&rsquo;'Query string caching behavior&rsquo; settings what is listed below:</p>
<p><img src="/img/OptimizingAppServiceDeliveryAzureCDN/image5.png" alt="Image5"></p>
<p>There is a few options for the &lsquo;Query string caching behavior setting&rsquo; which are defined below:</p>
<ul>
<li>
<p>Ignore query strings - This will request the first query string from the origin server to the edge server but will ignore any other requests that come throw with the same query string.</p>
</li>
<li>
<p>Bypass caching for query strings - This will request the query string from the origin server to the edge server each time a request comes in. This will ignore caching all together.</p>
</li>
<li>
<p>Caching every unique URL - When a unique query string that is requested from the user will be cached from the origin server to the edge server.</p>
</li>
</ul>
<p>Under custom caching settings we can setup specific caching rules for specific file paths or file extensions. I am going to specify a specific path that I want to ignore caching on. This will allow the user to pull the most recent files from a specific path on my Web App each time a request comes through. Essentially, this is sending a request directly to the origin server each time when a specific path is called.</p>
<p>Let save the settings but keep in mind some of these settings will not propagate for 90 minutes. This is the issue when testing these setting because it will take time for those settings to be updated.</p>
<p>Purging Cache</p>
<p>Navigate to the Azure CDN setting for your content that you are sharing. On the top of the screen click on the purge button. Here we can purge the data stored on the edge server. In our case we updated an image and uploaded it to the origin server but the edge server still has the old image cached. We will choose the predefined endpoint pointing to our origin server and clear the images path.</p>
<p><img src="/img/OptimizingAppServiceDeliveryAzureCDN/image6.png" alt="Image6"></p>
<p>There is a maximum 50 limit request for each purge. The purge usually takes around 2-3 minutes but that is dependent on how much content we are purging on the edge server. We have been talking mainly about static data but in this next section we will talk about dynamic data with Dynamic Site Acceleration but will not configure it in Azure.</p>
<p>Dynamic Site Acceleration</p>
<p>Dynamic data in response to user&rsquo;s requests or behavior. This allows the users request to change the data that is being retrieved from the origin server on demand. Dynamic Site Acceleration is only offered on specific pricing tiers listed below:</p>
<ul>
<li>
<p>Version Standard</p>
</li>
<li>
<p>Version Premium</p>
</li>
<li>
<p>Akamai</p>
</li>
</ul>
<p>Dynamic Site Acceleration has two approaches.</p>
<ul>
<li>
<p>Rout Optimization - This finds the fastest route from the edge servers to the origin servers. This compares routes from POP locations and finds the most optimized route to retrieve data to the end user.</p>
</li>
<li>
<p>TCP Optimization - This is an algorithm that prevents network congestion. This limits the data sent over internet until packets are lost.</p>
</li>
</ul>
<p>To configure Dynamic Site Acceleration, we will need to upload a probe file. Caching is turned off by default for Dynamic Site Acceleration, however, we can turn it on for specific file paths.</p>
<p>We have talked how Azure CDN works and how to create profiles that store endpoints to point to content origin servers. For the last blog in this series we will talk about how to monitor and diagnose issue with App Service plans in Azure.</p>
<p>Until next time! Cheers!</p>
<p>Jared Clark</p>
]]></content>
		</item>
		
		<item>
			<title>Scaling Up and Down App Service Plans</title>
			<link>https://jaredclark0626.github.io/posts/scaling-up-and-down-app-service-plans/</link>
			<pubDate>Sun, 26 Apr 2020 08:32:52 -0400</pubDate>
			
			<guid>https://jaredclark0626.github.io/posts/scaling-up-and-down-app-service-plans/</guid>
			<description>Short-hand:
 ASE - App Service Environment  This will be a short blog since I will be only giving a brief overview of scaling up and down App Service plans. We will talk about how to scale up and down app service plans manually and automate scaling depending on workload. First, I want to give you a general overview of scaling up and down app services.
Overview of Scaling Up and Down App Service Plans</description>
			<content type="html"><![CDATA[<p>Short-hand:</p>
<ul>
<li>ASE - App Service Environment</li>
</ul>
<p>This will be a short blog since I will be only giving a brief overview of scaling up and down App Service plans. We will talk about how to scale up and down app service plans manually and automate scaling depending on workload. First, I want to give you a general overview of scaling up and down app services.</p>
<p>Overview of Scaling Up and Down App Service Plans</p>
<p><img src="/img/ScalingUpDownAppServicePlan/image1.png" alt="Image1"></p>
<p>Scaling up also referred to as vertical scaling is tied to the Azure tier level you have set on your App Service Plan. Scaling up cost more because we are adding more compute resources such as CPU and Memory for our App Services to run on. There is an option to scale up to an isolated network (ASE) but keep in mind you Apps Services Plan can become costly. Another reason to scale up would be Azure adds more features to your App Service Plan as you scale up. Higher plans equels more features unlocked for your App Service Plan. One of the mmost important features would be deployment slots which is available at the Standard pricing teir.</p>
<p>Azure Deployment slots are actually live app with their own hostname. The main reason for deployment slots in an App Service Plan is to have multiple environments for development teams to deploy to such as the following.</p>
<ul>
<li>
<p>Dev Environment</p>
</li>
<li>
<p>QA Environment</p>
</li>
<li>
<p>UAT Environment</p>
</li>
<li>
<p>Production Environment</p>
</li>
<li>
<p>Canary Ring Environment</p>
</li>
</ul>
<p>This allows development teams working on different features to deploy to specific environments at the same time. Additionally, this allows for deployment slots developers can validate app changes in DEV and QA environments before swapping the feature into production.</p>
<p>App Service Plan also define the maximum number of instances you can have so you might scale up to the premium plan just so you can scale out. There are quotas for each tier for App Service Plan which is linked below.</p>
<p>Azure App Service Plan Tiers Link: <a href="https://azure.microsoft.com/en-us/pricing/details/app-service/windows/">https://azure.microsoft.com/en-us/pricing/details/app-service/windows/</a></p>
<p>If you reach the bandwidth limits on free or shared App Service Plan tiers your app will receive a 403 error. You will either have to wait until the quota resets or upgrade you App Service Plan. Essentially what is happening when you upgrade your App Service plan is the VMs(instances) your app is running on gets upgraded to bigger VMs with more compute resources. Scaling up can take anywhere between a few seconds and up to five minutes to complete. This is all dependent on which tier you are upgrading to and the workload running on you App Service Plan.</p>
<p>In terms of scaling up I would start at the lowest tier possible and scale up as needed. This means continuous monitoring of your App Service plan which we will talk about in an upcoming blog. When scaling up we want to think about maintenance windows during this time since the apps and jobs running on those can stop and be re-done when the scaling up process is completed. This means our jobs that we create for our app will need to be intelligent enough to know when a scale up is about to occur and gracefully shutdown before scale up begins.</p>
<p>To see if you have reached your storage quota on you App Service Plan tier you can log into Azure and open the App Service Plan. Navigate to the &lsquo;File System Storage&rsquo;, here you can see the threshold and usage of the storage your App Service plan has consumed.</p>
<p><img src="/img/ScalingUpDownAppServicePlan/image3.png" alt="Image3"></p>
<p>Keep in mind that is the quota for the App Service Plan not the App Service running on that plan. To explicitly look at the storage quota for the App Service you will need to click on the App tab in the App Service plan page and select your app. Once you have selected your app, you can navigate to the quotas tab which is where you will see the Storage (File system usage) for that specific app.</p>
<p><img src="/img/ScalingUpDownAppServicePlan/image4.png" alt="Image4"></p>
<p>This page shows your resources quotas, what has been used, and when the quota resets. This is helpful when you are trying to determine when it is time to scale up to a new tier.</p>
<p>Scaling Up App Service Plan</p>
<p>Navigate to your App Service Plan that you would like to scale up and select the &lsquo;Scale up (App Service Plan) tab. Here you will have the options to scale up or down your App Service Plan. Keep in mind when you scale down you App Service Plan you may lose features available at that tier. We are going to scale up to the &lsquo;Shared Infrastructure&rsquo; tier under the &lsquo;Dev/Test&rsquo; tab. This will give us more compute time (240 minutes per day). Select the D1 pricing tier and click apply.</p>
<p><img src="/img/ScalingUpDownAppServicePlan/image5.png" alt="Image5"></p>
<p>Keep in mind scaling up or down may take some time depending on the workload you have running on your apps running on the App Service Plan. Now let&rsquo;s scale back down to the F1 pricing tier. Select F1 tier and click apply. It&rsquo;s as simple as that when scaling up and down your App Service Plans. Now let&rsquo;s talk about scaling out App Service Plans and something really cool, auto-scaling!</p>
<p>Overview of Scaling Out and Auto-scaling App Service Plans</p>
<p><img src="/img/ScalingUpDownAppServicePlan/image2.png" alt="Image2"></p>
<p>Scaling out App Service Plans is defined as adding more instances (VMs) to your app Service Plan. Instead of adding more compute resources to your App Service plan we are adding more instances (VMs). Scaling out is allows referred to Horizontal Scaling. The maximum number of instances you can have on an App Service Plan is 100 instances which is available on the Isolated (ASE) tier. If you need more instances allocated to an App Service Plan you can call Microsoft support or submit a support ticket.</p>
<p>Auto-scaling allows your App Service Plan to have the right amount of resources available to run and handling workloads running on your apps. It allows you to provision and de-provision VMs and resources depending on the workload running on your app. You specify a maximum and minimum number or instances to add or remove automatically depending on demand. This allows for natural growth of your App Service Plan and saves you money in the long run. For example, let&rsquo;s say you have a web app that sees high traffic from 9AM to 1PM by configuring auto-scaling your web app will have enough resources to handle that workload during those times. Since the web app scales out during those hours your end users are happy because they are not staring at loading screens. We all know what that means happy customers equals more money.</p>
<p>We can set up auto-scaling based on metrics such as CPU usage, Memory usage, Disk queue length, Ingress/egress data, and application insights. Additionally, like mentioned above in the example we can auto-scale based on a time-frame or date we configure. We can also set up auto-scaling to send us a message when the App Service plan is scaling. Keep in mind when scaling out all your web apps are running on each provisioned instance (VMs) which means if you have a non-busy web app running on the same App Service plan as busy apps they will be provisioned too. We can configure specific web apps to be provisioned based on auto-scaling (Per-App Auto-scaling) but that is an advanced topic that we will not discuss in this blog.</p>
<p>When designing application, we want to design them stateless to take advantage of auto-scaling. We can run into an issue referred to as session-affinity which means a user session will continue sending requests to a specific instance (VMs) even after auto-scaling. We can configure the a load balancer to route the users requests to different instances in the que to help Combate session-affinity. Another thing to note is the auto-scaling feature is only available at the standard level pricing tier. There are several options on how to configure auto-scaling which are listed below.</p>
<ul>
<li>
<p>Azure Portal</p>
</li>
<li>
<p>Azure CLI</p>
</li>
<li>
<p>Azure ARM Templates</p>
</li>
<li>
<p>PowerShell</p>
</li>
<li>
<p>Azure REST API</p>
</li>
</ul>
<p>Setting up Auto-scaling App Service Plan</p>
<p>Navigate to your App Service Plan and click on the &lsquo;Scale out (App Service Plan)&rsquo; tab. Here you will have an option to perform a manual scale out of a custom auto-scale. If you want to perform a manual scale out, select that option and change the &lsquo;Instance count&rsquo; to how many instances (VMs) you would like to scale-out. Alternatively, we can enable auto-scaling. By selecting that option, a set of parameters will appear to set up an auto-scaling condition. We can keep the default name and the default resource group.</p>
<p>There are two options for the &lsquo;Scale Mode&rsquo;, one being &lsquo;Scale based on metric&rsquo; and another being &lsquo;Scale to a specific instance count&rsquo;. We can scale up and add another instance by choosing the &lsquo;Scale to a specific instance count&rsquo; then setting the &lsquo;Instance count&rsquo; to 1. We can add multiple auto-scale condition by clicking the &lsquo;Add a scale condition&rsquo; link. Let&rsquo;s select the &lsquo;Scale based on metric&rsquo; option and set our min and max instance (VM) limits. There is a default parameter that is set to 1 which indicates that at all time there will always be 1 instance online and available. There is an option to tie a schedule to the auto-scaling condition as well. In our case we will set it between 6 AM and 6 PM.</p>
<p>Under &lsquo;Rules&rsquo; lets add a rule that the condition will ad-hear to. A new window will open on the right-hand side of the screen. The &lsquo;Metric resource&rsquo; option refers to the resource we would like this condition to be applied too. In our case we will keep it set to &lsquo;Current resource&rsquo; and page down to the &lsquo;Actions&rsquo; section. The &lsquo;Operation&rsquo; we will set will be &lsquo;Increase count by&rsquo; and we want to set the &lsquo;Instance count&rsquo; equal to 1. The &lsquo;Cool down&rsquo; option refers to the amount of time after the condition has been met where the scale out condition will not be evaluated. We will set the &lsquo;Cool down&rsquo; to 5 minutes, which means for 5 minutes after we scale out to another instance the condition will be disabled. The &lsquo;Criteria&rsquo; section refers to what metrics have to be met to scale out our App Service Plan. The &lsquo;Criteria&rsquo; section can change depending on the scope we set at the &lsquo;Metric resource&rsquo; level of the condition. We will set the &lsquo;Time aggregation&rsquo; to average and keep the &lsquo;Metric namespace&rsquo; set to default (App Service Plan Standard Metrics). For the &lsquo;Metric name&rsquo; we will keep the default &lsquo;CPU percentage&rsquo;. Please note the &lsquo;1-minute time grain&rsquo; label under &lsquo;Metric name&rsquo; drop down, this refers to the average over a minute time-span. So, the condition evaluates the average CPU percentage of 1 minute.</p>
<p>For the &lsquo;operator&rsquo; we will set it equal to &lsquo;Greater than&rsquo; and the &lsquo;Metric Threshold to trigger scale action&rsquo; set to 70%. The &lsquo;Duration&rsquo; parameter we will set to 10 minutes. Now if the average 1-minute time space is greater than 70% for 10 minutes then this scale out condition will be met. We do have an option to set the &lsquo;Time grain statistic&rsquo; to another option but we will keep it at average. Click &lsquo;Add&rsquo; at the bottom of the screen to add the scale rule.</p>
<p><img src="/img/ScalingUpDownAppServicePlan/image6.png" alt="Image6"></p>
<p>There is a recommended option to add a &lsquo;Scale in&rsquo; rule set so the app service plan can scale back in to its original size. This is recommended because if that scale in rule is not set the app service plan will just scale out and stay at the size. We are not going to set that rule due to the scope of this demo but you can add a scale in rule by click on the recommended rule.</p>
<p>We talked about the b scaling up and down App Service plans. We also talked about how to scale up and down app service plans manually and how to set auto-scaling conditions. This is a great resource you can utilize when build out your app service plans which in the long run will save you money and make your customers happy.</p>
<p>Upcoming:</p>
<ul>
<li>
<p>Optimizing App Service Plan</p>
</li>
<li>
<p>Monitoring App Service Plans</p>
</li>
<li>
<p>Converting GUI build definition in YAML</p>
</li>
</ul>
]]></content>
		</item>
		
		<item>
			<title>Creating and deploying Microsoft Azure App Service Plan</title>
			<link>https://jaredclark0626.github.io/posts/managing-microsoft-azure-app-service-plan/</link>
			<pubDate>Fri, 17 Apr 2020 10:02:17 -0400</pubDate>
			
			<guid>https://jaredclark0626.github.io/posts/managing-microsoft-azure-app-service-plan/</guid>
			<description>tags:
 Azure Azure DevOps CI/CD Pipelines Azure App Service Plans  In this blog I will give you an overview of Microsoft App Service plans, how to create and app Service Plan and finally how to create an App Service. We will talk about options on how to deploy code to App Services. To kick this off let me give you an overview of Microsoft App Service Plan.
App Service Plan Overview</description>
			<content type="html"><![CDATA[<p>tags:</p>
<ul>
<li>Azure</li>
<li>Azure DevOps</li>
<li>CI/CD Pipelines</li>
<li>Azure App Service Plans</li>
</ul>
<p>In this blog I will give you an overview of Microsoft App Service plans, how to create and app Service Plan and finally how to create an App Service. We will talk about options on how to deploy code to App Services. To kick this off let me give you an overview of Microsoft App Service Plan.</p>
<p><img src="/img/AzureAppServicePlan/Image0.png" alt="Image0"></p>
<p>App Service Plan Overview</p>
<p>A Microsoft App Service Plan defines a set of compute resources for an App Service to run. Depending on the tier of the App Service Plan you choose you can run multiple App Services in a single App Service Plan. I have listed below what types of App Services you can run with in an App Service plan.</p>
<p>Apps Service types:</p>
<ul>
<li>Web Apps</li>
<li>API Apps</li>
<li>Mobile Apps</li>
<li>Function Apps</li>
</ul>
<p>App Services support a verity of languages such as:</p>
<ul>
<li>ASP.NET</li>
<li>ASP.NET Core</li>
<li>JAVA</li>
<li>Ruby</li>
<li>Node.js</li>
<li>PHP</li>
<li>Python</li>
</ul>
<p>I like to think of an App Service Plan as a container for App Service(s). You cannot have an App Service without an App Service plan. App Services define a set of compute resources that you App Service(s) can use.</p>
<p>App Service Plan defines:</p>
<ul>
<li>Azure region</li>
<li>Min/Max number of VM instances</li>
<li>Size of VM instances
<ul>
<li>CPU</li>
<li>RAM</li>
<li>Storage</li>
</ul>
</li>
<li>Pricing Tier</li>
</ul>
<p>Please note that you can change the App Service plan pricing tier after it is provisioned. This allows you to test and scale out/up you App Service plan on-demand. There are two types of scaling models within an App Service Plan. Scaling up refers to adding more resources VM instances where Scaling out refers to adding more VM&rsquo;s to the App Service Plan. With that said you can configure Auto-Scaling which can scale up or down depending on demand.</p>
<p>App service deployments</p>
<p>Multi-tenant Service allows you to deploy your App Service plan on a Shared Network infrastructure. This means you are sharing the network with other tenants in Azure. Alternatively, you can set up an App Service Environment (ASE) which you deploy your own VNET and have an isolated environment for you App Service Plan to run on. There is one more option for deployments and that is called Azure Stack deployment. This allows you to deploy your App Service plan on-premises.</p>
<p>Essentially, an App Service plan is a set of VM&rsquo;s. Each VM is known as an instance and each instance is hosting an App Service. Each instance has a C:\ and D:\ drive. The C:\ drive is used for temporary storage and the D:\ drive is used for sites code and log files. These drives aren&rsquo;t stored on each instance, instead they are hosted in a Storage Container and mapped to each instance. All instances in your App Service Plan have access to the D:\ drive. When deploying your code all instances will have access to the same code base via the D:\drive.</p>
<p>Every App runs as a low privileged worker process called the application pool identity. Apps are isolated within an App Service Plan. When using an App Service Plan, you don&rsquo;t have access to the underlying OS components such as:</p>
<ul>
<li>Registry</li>
<li>Cryptography subsystem</li>
<li>Graphics subsystem</li>
</ul>
<p>Now let&rsquo;s move onto creating an App Service Plan!</p>
<p>Creating an App Service Plan</p>
<p>Log into your azure account and search for App Service Plan. Once on the App Service Plan page, click &lsquo;Create App Service Plan&rsquo;. If you have a resource already created then choose that resource group to hold you App Service Plan. In our case we are going to create a new resource group by clicking on the &lsquo;Create new&rsquo; button. This name has to be unique within Azure. Type in the name of the resource group you would like to create and click create. Next, we will need to give the App Service Plan a name which does not need to be unique within Azure.</p>
<p>We will need to choose the underlying OS that our App Services will run on. We have the option of either Windows or Linux, keeping in mind that we will not be able to mix the two OS&rsquo;s in a single App Service Plan. We will stick with the Windows OS and EastUS region. For the pricing tier we will use the Dev/Test free pricing tier.</p>
<p><img src="/img/AzureAppServicePlan/Image1.png" alt="Image1"></p>
<p>Let&rsquo;s apply a &lsquo;Dev&rsquo;: &lsquo;Test&rsquo; tag to this App Service plan for easy configuration and maintenance. Click next and let&rsquo;s run the preliminary checks to verify the App Service Plan is configured correctly. Once the checks clear we can create the App Service plan by clicking the create button. Now we will not be able to create a Web App from inside the App Service Plan, we will need to create a new Web App Resource. Search for Web App in azure and click create new Web App. Here we will have an option to add the new Web App to the existing App Service Plan resource group or create a new resource group. For this demo we will add the Web App to the existing resource group for the App Service Plan.</p>
<p>We will need to name the Web App which will need to be unique across Azure. The name is prefixed with &lsquo;.azurewebsites.net&rsquo; prefix. We will have an option to publish the Web App via Code or a Docker container. We will publish the Web App using the Code option. There is an option for runtime which the Web App will use when running. Keep in mind some of these Runtimes can only be run on respective OS&rsquo;s. In our case we will use .NET Core 3.1 and choose the Windows OS. We will choose the East US for the region. This will find App Service Plan that we provisioned earlier and default to that App Service Plan. If you have multiple app Service plans be sure to choose the correct one.</p>
<p>Next, we will have an option to choose if we want to add monitoring to our Web App but in our case, we will turn off monitoring. We will apply a &lsquo;Dev&rsquo;:&lsquo;Test&rsquo; tag to our Web App can let the preliminary checks run. Once the checks pass, we can create the Web App. Next, I want to take a brief moment and talk to you about networking in regards to Web Apps and App Service Plans.</p>
<p>Networking</p>
<p>With the multi-tenet App Service plan, we use shared resources with one of them being a shared IP address. If you navigate to the Web App and choose Custom Domains you will find the shared IP address our Web App is using. Outbound traffic goes out to the internet through a set of outbound IP address, those IP address can be found on the Properties tab. App Services Access Restrictions restrict incoming network access from a range of IP address and/or virtual network subnet(s). This will block traffic from internet and only allow access from you VNET.</p>
<p>App Service Environment (ASE)</p>
<p>When you run your apps on &lsquo;Production&rsquo; or &lsquo;Isolated&rsquo; tiers you are using dedicated resources. In our case we are using the &lsquo;Dev/Test&rsquo; tier which uses shared resources. App Service Environment is only available on &lsquo;Production&rsquo; and &lsquo;Isolated&rsquo; tiers. This allows you to have an isolated network, massive scale-out options. DV2 VMs (Powerful VMs), access to on-premise environment, External ASE, and ILB ASE (no public internet access).</p>
<p>App Service Environments allow a max of 100 App Service plan instances. Those App Service Plans cam be distributed and you can have more then 100 App Service plan but you will need to call Microsoft support. Traffic manager can distribute requests between ASE instances and pricing is a flat rate opposed to pay what you use model.</p>
<p>Creating an App Service Environment (ASE)</p>
<p>Login to Azure and search for App Service Environment (ASE). Click create new App Service Environment. Let&rsquo;s create new resource group for the App Service Environment. I named my resource group &lsquo;ASE-RS-DEV-TEST&rsquo; and named the ASE instance &lsquo;ASE-DEV-TEST-JCLARK0909&rsquo; We are going to use an internal virtual IP type. Next, we will need to create a virtual network and subnet for the ASE instance to run on. We will need to add a subnet address block which will be the virtual network address block prefixed with &lsquo;.0/28&rsquo; Lets add a &lsquo;Dev&rsquo;:&lsquo;Test&rsquo; tag. Alternatively, you do not need to create an App Service Environment (ASE) since it is costly, we can stick with the free dev/test pricing tier.</p>
<p>Deploying an App Service</p>
<p>First, let&rsquo;s discuss the deployment options for deploying apps to an app service plan. We will run through a few option for deploying code to an app service listed below:</p>
<ul>
<li>
<p>Azure CLI</p>
</li>
<li>
<p>&ldquo;Run from package&rdquo; from Azure Storage</p>
</li>
<li>
<p>Azure DevOps CI/CD pipeline</p>
</li>
</ul>
<p>Azure CLI Deployment</p>
<p>First let&rsquo;s start by deploying code with Azure CLI. There is a few option when using Azure CLI. You can either login to Azure and use the cloud shell feature which requires a storage container. Alternatively, you can download the Azure CLI to your local machine and run the commands from your local environment. I will be running these commands from my local machine.</p>
<p>Link to download Azure CLI: <a href="https://docs.microsoft.com/en-us/cli/azure/install-azure-cli?view=azure-cli-latest">https://docs.microsoft.com/en-us/cli/azure/install-azure-cli?view=azure-cli-latest</a></p>
<p>Once downloaded we want to run Command prompt as administrator and run the following command to login.</p>
<p>CMD: az login</p>
<p>A new window will open where you can authenticate to your Azure subscription. You want to verify that the account you are authenticating with has administrator rights to the App Service Plan and the App Service.</p>
<p>Log into Visual Studio and open your solution file. Once opened we can build the solution and right click on the Web app in the solution explorer then click publish. On this screen we will have a few option on where we want to publish the output of our web app build. In our case we are going to publish the web app to a local folder and use the Azure CLI to upload it to the App Service.</p>
<p>I<img src="/img/AzureAppServicePlan/Image2.png" alt="Image2"></p>
<p>Once you published the web app to a local folder, we need to compress it into a zip file. Right click and choose to send it to a compressed folder. Now we are ready to upload the zip folder via Azure CLI to our App Service. Below I have listed a few parameters and their descriptions.</p>
<ul>
<li>
<p>&ndash;resource-group = Azure resource group</p>
</li>
<li>
<p>&ndash;name = Azure App Service</p>
</li>
<li>
<p>&ndash;src = Path to zip folder</p>
</li>
<li>
<p>config-zip = Azure parameter for uploading zip folder</p>
</li>
</ul>
<p>CMD: az webapp deployment source config-zip &ndash;resource-group TestAppServicePlan &ndash;name TestWebApp0909 &ndash;src &ldquo;C:\repo\Azure\AppServicePlan\03\demos\code1\PSWebApp\PSWebApp\bin\Release\netcoreapp2.1\publish\deployment.zip&rdquo;</p>
<p>It will take a few second’s for to upload the zip folder to azure and KUDO to unzip the folder. To verify you have successfully deployed the app service plan via Azure CLI you will get back meta data about the deployment in the CMD windows.</p>
<p>Note: There is an item listed in the meta data called &lsquo;Complete&rsquo; that lets you know if the deployment was successful. Also, there is a &lsquo;log_URL&rsquo; which will point the log file for the deployment. I found the log file to be helpful when troubleshooting failed deployments.</p>
<p><img src="/img/AzureAppServicePlan/Image3.png" alt="Image3"></p>
<p>Azure Storage Deployment</p>
<p>To make things easier let&rsquo;s install Microsoft Azure Storage Explorer.</p>
<p>Download link: <a href="https://azure.microsoft.com/en-us/features/storage-explorer/">https://azure.microsoft.com/en-us/features/storage-explorer/</a></p>
<p>Once Azure Storage Explorer is installed, we will need to sync it to our Azure subscription. On the left-hand side of the screen you will see you Azure storage resources. Now, we need to create an Azure Storage account to store the contents our Web App. Log into Azure and search storage accounts. Click create new storage account then use the App Service Plan resource group or create a new resource group. In our case we will be using the existing App Service Plan resource group. Name the storage account and place it in the same region as the App Service Plan. Let&rsquo;s select &lsquo;BlobStorage&rsquo; and &lsquo;Local-redundant storage (LRS)'. For the access tier lets select &lsquo;cool&rsquo; and click next. On the networking tab we can use the default which is &lsquo;Public endpoint (all networks)'. Use the default for the security section and add the &lsquo;Dev&rsquo;:&lsquo;test&rsquo; tag to the storage account. Let the preliminary checks run and create the storage account.</p>
<p><img src="/img/AzureAppServicePlan/Image4.png" alt="Image4"></p>
<p>Open the storage account and click on containers then create a new container called &lsquo;zip&rsquo;. Here will be where we upload the contents of our web app. When you create the container make sure to set the &lsquo;Public access level&rsquo; to blob. Open Azure Storage explorer and navigate to the zip blob container then drag and drop the zip folder with our web app.</p>
<p><img src="/img/AzureAppServicePlan/Image5.png" alt="Image5"></p>
<p>The container access is set to private which means no one can&rsquo;t get to this storage account without a token. Right click on the zip folder in azure storage explorer and select &lsquo;Get Shared Access Signature&rsquo;. A new window will appear where we can set some permissions explicitly on this container. The app service needs read access to the storage container. Let&rsquo;s add that permission to the storage container and set the Expiry time from a year from now. If this is production you will want to set a longer Expiry time.</p>
<p><img src="/img/AzureAppServicePlan/Image6.png" alt="Image6"></p>
<p>Another window will open which the storage account URL with the starred access token appended to it. Copy that URL as a query string parameter and open the web app in azure portal. Navigate to configuration and we need to add a new App setting. Click the plus next to &lsquo;New Application Setting&rsquo; and add the following parameter with the copied shared access token URL as the value.</p>
<p>Parameter: WEBSITE_RUN_FROM_PACKAGE</p>
<p>Refresh the App Service endpoint URL and now the app service is deployed with using and Azure Storage Account. Whenever that storage account is updated it will deploy the contents of the storage account. Now the site is running from a zip from stored on Azure App Storage.</p>
<p>Azure DevOps (ADO) CI/CD pipeline Deployments</p>
<p>Azure DevOps is going to gives a robust set of features for building and deploying out projects. This will allow us to setup build pipelines that automatically trigger build when developers check in code to the repository. It will allow us to capture a build artifact when then we can deploy it to multiple environments with release pipelines. Let&rsquo;s start by logging into Azure DevOps and creating a new project. I will call my project WebApp. You will need to specify the source repository for you project. We will be using git to store our repository and work item process will be set to agile.</p>
<p><img src="/img/AzureAppServicePlan/Image7.png" alt="Image7"></p>
<p>The source files get stored in the repository section of ADO. We are going to want to deploy our code to Azure App service but to do that we need to go to settings and configure our connection to Azure. Click on project settings on the bottom left-hand side of the screen and navigate to &lsquo;Source Settings&rsquo;. Click &lsquo;Create New Service Connection&rsquo; and select &lsquo;Azure Resource Manager&rsquo; then select &lsquo;Service Principle(automatic). Add the Azure Subscription ID and name the service connection &lsquo;Azure Connection&rsquo;. You have an option to scope the Service connection to a resource group but in our case, we will scope to service connection to the entire Azure subscription by leaving the resource group option blank.</p>
<p><img src="/img/AzureAppServicePlan/Image8.png" alt="Image8"></p>
<p>Click save to save the service connection settings to azure and navigate to &lsquo;Pipelines&rsquo; then &lsquo;Builds (Pipelines)'. Here we will select our source repository for our web app. We will be using the legacy build pipelines to get started and migrate to YAML. On the bottom of the screen on the builds(pipelines) tab click &lsquo;Use Classic Editor&rsquo;. Keep the default &lsquo;Azure Repos Git&rsquo; and default settings then click continue. Let&rsquo;s use the template for ASP.NET Core app and apply. Now we get a pre-configured build pipelines with a few task. Under the &lsquo;Pipelines&rsquo; section lets choose the Hosted Azure DevOps agent pool. Under &lsquo;Agent Specification&rsquo; choose &lsquo;vs2017-win2016&rsquo;.</p>
<p><img src="/img/AzureAppServicePlan/Image9.png" alt="Image9"></p>
<p>There is a few predefined task in the ASP.NET Core build template. First, we are going to run a restore then we will build the solution and test. We do not have tests at this point in time so we can disable that task by right clicking on it and disabling it. Next, we are running a Publish task followed by a publish artifact task. Let&rsquo;s save the build definition and navigate to the &lsquo;Triggers&rsquo; tab on top of the screen. This is where we can set Continuous Integration build triggers CI triggers for short. For example, let&rsquo;s say a developer is working on a feature branch called &lsquo;feature/thisFeatureIsAwesome&rsquo; and they check in code to that feature branch. There will be no automatic builds after the check-in without any CI triggers. The developer adds a CI trigger called &lsquo;featuure/thisFeatureIsAwesome&rsquo; to the build definition. Now when they check in code to that feature branch it will automatically trigger a build for continuous integration. Alternatively, if you have a scheduled time for a build to be run you can set up a CI trigger to run a build at a specific time.</p>
<p><img src="/img/AzureAppServicePlan/Image10.png" alt="Image10"></p>
<p>now that the build definition is completed lets created the release definition to upload our code to the Azure App Service. Expand the Pipelines tab in ADO and select releases. Click the option to &lsquo;Create New Release Definition&rsquo; and search for the Azure App Service&rsquo; template. Click on the stage link to edit the tasks running in that stage. On the &lsquo;Stage 1&rsquo; tab we will need to modify some of the parameters. Change the &lsquo;Azure Subscription&rsquo; parameter to point to the Azure Service connection we created earlier. Select the App Service name we would like to deploy to and click on the &lsquo;Deploy Azure App Service&rsquo; task. Here there are a lot of options which we will discuss in another blog but for the purposes of this blog let&rsquo;s keep the default settings.</p>
<p>Let go back to the Pipeline tab on the top left side of the screen and add a build artifact. Click on the plus sign next to the artifacts on the left-hand side of the screen. Here we want to add the Web App build artifact from the build. Choose the project and source build then keep the default version as &lsquo;Latest&rsquo; Keep the &lsquo;_&rsquo; in the source alias and click &lsquo;Add&rsquo;.</p>
<p><img src="/img/AzureAppServicePlan/Image11.png" alt="Image11"></p>
<p>Next to the build artifact there is a &lsquo;Lighting Bolt&rsquo;. If you select that option it will allow you to set Continuous Deployment Triggers, CD triggers for short. This allows the deployment of your web app to be automated when a new build artifact is available. Let, go ahead and enable the CD Trigger for this release definition. Next, we will need to install git if you do not already have it installed.</p>
<p>Git Download: <a href="https://git-scm.com/downloads">https://git-scm.com/downloads</a></p>
<p>Once downloaded we can save our changes in Visual Studio and close it. Let&rsquo;s re-open Visual Studios and open our solution file. On the bottom right-hand side of the screen you will see and option to add source control. There should only be one option which is &lsquo;Git&rsquo;. Select it and a new &lsquo;Team Explorer&rsquo; window will open in VS. Since we have already created a repository in ADO we will expand the &lsquo;Push to Remote Repository&rsquo; option and select &lsquo;Publish Git Repo&rsquo;. There will be an option to enter the repository URL for the existing repository. We need to ADO and navigate to the repository section and grab the Azure Pipelines Git URL. Select the URL under &lsquo;Clone to your computer&rsquo; and paste it into VS. Click the publish button and refresh the ADO repository page. See now the repository has been synchronized with our local repository.</p>
<p>Almost done, I promise! Let&rsquo;s enable CI on the build definition. Open the Web App build definition and select the triggers tab. Enable the &lsquo;Enable Continuous Integration&rsquo; option and verify the branch filter is set to &lsquo;include&rsquo;:&lsquo;master&rsquo; and save. Let&rsquo;s make a simple change to our web app and commit the changes to the local repository and push those changes to the master branch.</p>
<p><img src="/img/AzureAppServicePlan/Image12.png" alt="Image12"></p>
<p>Refresh the ADO build pipelines tab to watch the build get queued, built, and deployed.</p>
<p>Build Pipeline logs:</p>
<p><img src="/img/AzureAppServicePlan/Image13.png" alt="Image13"></p>
<p>Release Pipeline logs:</p>
<p><img src="/img/AzureAppServicePlan/Image14.png" alt="Image14"></p>
<p>Now let&rsquo;s log back into Azure and check to see if our App Service was deployed.</p>
<p>Eureka! We did it!! We have successfully deployed our web app with Azure DevOps full CI/CD pipeline. I hope you enjoyed this blog and will see you in the next one.</p>
<p>Upcoming:</p>
<ul>
<li>Scaling up/down App Service Plans</li>
<li>Optimizing App Service Plan</li>
<li>Monitoring App Service Plans</li>
<li>Converting GUI build definition in YAML</li>
</ul>
<p>Notes:</p>
<ul>
<li>You can access the KUDO site by inserting &lsquo;scm&rsquo; between the App Service name and azure website prefix.</li>
<li>You can have multiple CI/CD triggers for each build and release definition.</li>
<li>Depending on the repository branching strategies you use the * symbol allows for any build or release to automatically deploy builds/releases. For example:
<ul>
<li>release/* - This will trigger any builds/releases off the release branch.</li>
<li>feature/* - This will trigger any builds/release off the feature branch.</li>
</ul>
</li>
<li>You can exclude branches from being automatically built by using the &lsquo;Exclude&rsquo; option.</li>
<li>If you want to convert this GUI build definition into YAML, you will need to create an &lsquo;azure-pipelines.yml&rsquo; file and place it into the root directory of your repository. To copy the YAML syntax over to the YAML file you will need to open the build/release definition and select the &lsquo;View YAML&rsquo; option. Copy the YAML syntax over to the YAML build definition and perform an &lsquo;initial commit&rsquo;. Verify a build has been queued an you are done. There is alot more you need to know about converting GUI based build definitions but we will talk about that in a later blog.</li>
</ul>
<p>References:</p>
<ul>
<li><a href="https://app.pluralsight.com/profile/author/neil-morrissey">https://app.pluralsight.com/profile/author/neil-morrissey</a></li>
</ul>
]]></content>
		</item>
		
	</channel>
</rss>
